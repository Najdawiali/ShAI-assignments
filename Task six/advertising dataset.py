# -*- coding: utf-8 -*-
"""Copy of task_7_exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x_ep5wlM5ylYtgOp4ja45lEM6ezxnJoH

___

# Logistic Regression Project

In this project we will be working with a fake advertising data set, indicating whether or not a particular internet user clicked on an Advertisement. We will try to create a model that will predict whether or not they will click on an ad based off the features of that user.

This data set contains the following features:

* 'Daily Time Spent on Site': consumer time on site in minutes
* 'Age': cutomer age in years
* 'Area Income': Avg. Income of geographical area of consumer
* 'Daily Internet Usage': Avg. minutes a day consumer is on the internet
* 'Ad Topic Line': Headline of the advertisement
* 'City': City of consumer
* 'Male': Whether or not consumer was male
* 'Country': Country of consumer
* 'Timestamp': Time at which consumer clicked on Ad or closed window
* 'Clicked on Ad': 0 or 1 indicated clicking on Ad

## Import Libraries

**Import a few libraries you think you'll need (Or just import them as you go along!)**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## Get the Data
**Read in the advertising.csv file and set it to a data frame called ad_data.**
"""

df = pd.read_csv('advertising.csv')

"""**Check the head of ad_data**"""

df.head()

"""** Use info and describe() on ad_data**"""

df.dtypes

df.describe()

"""## Exploratory Data Analysis

Let's use seaborn to explore the data!

Try recreating the plots shown below!

** Create a histogram of the Age**
"""

df['Age'].hist(bins=30)
plt.xlabel('Age')
plt.show()



"""**Create a jointplot showing Area Income versus Age.**"""

sns.jointplot(x=df['Age'], y=df['Area Income'])
plt.show()



"""**Create a jointplot showing the kde distributions of Daily Time spent on site vs. Age.**"""

sns.jointplot(x=df['Age'], y=df['Daily Time Spent on Site'],kind = "kde",fill=True, thresh=0, cmap='Reds',color='red')
plt.show()



"""** Create a jointplot of 'Daily Time Spent on Site' vs. 'Daily Internet Usage'**"""

sns.jointplot(x=df['Daily Time Spent on Site'], y=df['Daily Internet Usage'],height=5,ratio=3,color='green',marginal_ticks=True)
plt.show()



"""** Finally, create a pairplot with the hue defined by the 'Clicked on Ad' column feature.**"""

sns.pairplot(df, hue='Clicked on Ad',palette='husl')
plt.show()



"""# Logistic Regression

Now it's time to do a train test split, and train our model!

You'll have the freedom here to choose columns that you want to train on!

** Split the data into training set and testing set using train_test_split**
"""

X = df[['Daily Time Spent on Site','Age','Area Income','Daily Internet Usage','Male']]
y = df['Clicked on Ad']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

"""feature scaling"""

from sklearn.preprocessing import StandardScaler

"""** Train and fit a logistic regression model on the training set.**"""

scaler = StandardScaler()

X_train_sca = scaler.fit_transform(X_train)

"""logistic regression hyperparameters tuning

https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/
"""

X_test_sca = scaler.transform(X_test)

"""## Predictions and Evaluations
** Now predict values for the testing data.**
"""

from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()

logreg.fit(X_train_sca,y_train)

prel = logreg.predict(X_test_sca)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,prel)

"""** Create a Confusion Matrix for the model.**"""

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test,prel)

"""## k-Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

KNN = KNeighborsClassifier(n_neighbors=5)

KNN.fit(X_train_sca,y_train)

preK = KNN.predict(X_test_sca)

accuracy_score(y_test,preK)



"""##random forest classifier"""

from sklearn.ensemble import RandomForestClassifier

ras = RandomForestClassifier(n_estimators=100)

ras.fit(X_train_sca,y_train)

prer = ras.predict(X_test_sca)

accuracy_score(y_test,prer)



"""## Great Job!"""