# -*- coding: utf-8 -*-
"""Copy of task_8_exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10bk4xJxO0C9nmsE_Aea6KsYG9-aWSbLl

# shAI Training 2023 | Level 1


## Task#10 (MNIST Project)

### Classification

- Before you start make sure you have latest Jupyter notebook version
- <font color= red> If you have older version fetching the data might be different  </font>

## Get tha dataset
"""

import sklearn.datasets

# CODE HERE
# IF you got stuck use GOOGLE
from sklearn.datasets import fetch_openml
mnist = fetch_openml('mnist_784',as_frame=False)

"""### exploring and preparing the dataset

#### print your dataset to get insight
"""

# CODE HERE
print(mnist)

"""#### Split you data into data and labels (target)"""

# CODE HERE
X, y = mnist["data"], mnist["target"]

"""#### find the data shape using .shape function"""

# CODE HERE
X.shape

"""### Peek at one digit from the dataset"""

import matplotlib
import matplotlib.pyplot as plt

"""***NOTE: ALL THE COMMANDS FOR PLOTTING A FIGURE SHOULD ALL GO IN THE SAME CELL. SEPARATING THEM OUT INTO MULTIPLE CELLS MAY CAUSE NOTHING TO SHOW UP.***"""

!install tensorflow
!install keras

X[399].shape

digit = X[40000]
digit_reshaped = digit.reshape(28, 28)
plt.imshow(digit_reshaped, cmap = matplotlib.cm.binary, interpolation="nearest")
plt.axis("off")
plt.show()

# CODE HERE

"""#### Split the data into train and test set"""

import numpy as np

# CODE HERE
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Shuffling the training set"""

#hint shuffle-vs-permutation-numpy
# CODE HERE
X_train_shuffled = np.random.shuffle(X_train)
y_train_shuffled = np.random.shuffle(y_train)

"""#### access the label of the above digit image"""

digit_label = y[40000]

digit_label

# CODE HERE

"""### Training a <font color= red>Binary</font> classifier

:#### Create the target vectors for this classification task
***NOTE : you can try different number.***
"""

mask = y == '5'

# Select rows and corresponding labels from X and y using the mask
X_5 = X[mask]
y_5 = y[mask]

y_5

"""### SGD classifier"""

y_5

"""#### Create a SGD classifier"""

from sklearn.linear_model import SGDClassifier

# CODE HERE
sgd_clf = SGDClassifier(random_state=42, loss='log')

"""#### use SGD classifier  to detect images of the number 5"""

# CODE HERE
sgd_clf.fit(X_train, y_train)

q = sgd_clf.predict(X_5)

q

y_5.shape

"""## Performance measure

####  Measuring Accuracy Using <font color= blue>Cross-validation</font>
"""

from sklearn.model_selection import cross_val_score

cross_val_score(sgd_clf, X_train, y_train, cv=5, scoring="accuracy")

"""#### Try a dumb classifier"""

# CODE HERE
from sklearn.dummy import DummyClassifier
dummy_clf = DummyClassifier()
dummy_clf.fit(X_train, y_train)

"""#### find cross_val_score for the dumb classifier"""

#CODE HERE
cross_val_score(dummy_clf, X_train, y_train, cv=3, scoring="accuracy")

"""## Confusion matrix"""

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

"""#### try to find confusion matrix"""

# CODE HERE
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)
confusion_matrix(y_train, y_train_pred)

"""####  try perfect classifier which will have only true positives and true negative

"""

# CODE HERE
y_train_perfect_predictions = y_train
confusion_matrix(y_train, y_train_perfect_predictions)

"""## Precision and Recall"""

from sklearn.metrics import precision_score, recall_score,f1_score

"""***Note that precision and recall score might be different from one to anothor***

#### find precision score
"""

# CODE HERE
precision_score(y_train, y_train_pred,average='micro')

"""#### find recall score"""

# CODE HERE
recall_score(y_train, y_train_pred,average='micro')

"""#### find f1 score
***Notice that f1 score is harmonic mean between recall and precision***
"""

# CODE HERE
f1_score(y_train, y_train_pred,average='macro')

"""# Precision/Recall Tradeof

#### try to use decision_function() and make prediction
"""

# CODE HERE
y_scores = sgd_clf.decision_function([digit])
y_scores

"""#### Set the threshold to zero"""

# CODE HERE
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred

"""#### Set the threshold to 200000"""

# CODE HERE
threshold = 200000
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred

"""#### To decide which threshold you want to use find decision scores for all instances"""

# CODE HERE
y_scores = cross_val_predict(sgd_clf, X_train, y_train, cv=3, method="predict_proba")[:, 1]



Y_scores = sgd_clf.predict_proba(X_train_5)[:, 1]

import numpy as np

Y_scores = np.nan_to_num(Y_scores)

y_train_5 = np.nan_to_num(y_train_5)

y_scores.shape

y_5.shape

from sklearn.model_selection import train_test_split
X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X_5, y_5, test_size=0.2, random_state=42)

y_train_5_binary = [1 if val == '5' else 0 for val in y_train_5]

# Calculate precision-recall curve with modified labels
precisions, recalls, thresholds = precision_recall_curve(y_train_5_binary, Y_scores)

len(y_train_5_binary)

"""#### computing precision and recall for all possible thresholds using the precision_recall_curve()"""

from sklearn.metrics import precision_recall_curve
precisions, recalls, thresholds = precision_recall_curve(y_train_5_binary, Y_scores)

"""#### plot precision and recall as functions of the threshold value using Matplotlib"""

# CODE HERE
plt.figure(figsize=(10,5))
plt.plot(thresholds, precisions[:-1], "b--", label="Precision")
plt.plot(thresholds, recalls[:-1], "g-", label="Recall")

"""#### lets aim for 90%recall
#### try different threshold and see what will happen

#### precision score
"""

# CODE HERE
threshold_90_precision = thresholds[np.argmax(precisions >= 0.9)]
threshold_90_precision

"""#### recall score"""

#CODE HERE
threshold_90_recall = thresholds[np.argmax(recalls >= 0.9)]
threshold_90_recall

y_scores.reshape(1,-1)

"""# The ROC Curve"""

from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_5, y_scores)

"""#### plot the FPR against the TPR using Matplotlib"""

# CODE HERE

"""#### computing the ROC AUC score"""

from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_5, y_scores)

"""# RandomForest Classifier
#### train a RandomForestClassifier and compare its ROC curve and ROC AUC score to the SGDClassifier
"""

from sklearn.ensemble import RandomForestClassifier

# CODE HERE

"""#### try to plot ROC
***Notice that you will need scores not probabilities***
"""

# CODE HERE
# if you got suck use GOOGLE

"""#### find ROC AUC score for randomforestclassifier"""

# CODE HERE

"""
# Congrats you did it ðŸ¥³ !
# #shAI_Club"""

